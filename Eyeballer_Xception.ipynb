{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuillBla/Internship_Report_Code/blob/main/Eyeballer_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A script to execute to prevent from the limits of imposed by Google Colab"
      ],
      "metadata": {
        "id": "wtxyezhW0ILg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function ConnectButton(){\n",
        "#     console.log(\"Connect pushed\"); \n",
        "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "# }\n",
        "# setInterval(ConnectButton,60000);"
      ],
      "metadata": {
        "id": "fuXNS5wr0Fw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdUx7FaCoYNX"
      },
      "outputs": [],
      "source": [
        "!pip install livelossplot\n",
        "!pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os,shutil\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Dense, Dropout, Flatten,Conv2D, GlobalAveragePooling2D\n",
        "from keras import regularizers\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from livelossplot.inputs.keras import PlotLossesCallback\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "Hf7B5Dzd0UyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SnH9s4gw0t2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the following folders have already been created, they need to be removed (uncomment if it is the case)"
      ],
      "metadata": {
        "id": "5-cadqNT0yIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Clear the environment\n",
        "# shutil.rmtree(r'/content/topic_classification_splitted')\n",
        "# shutil.rmtree(r'/content/topic_classification')"
      ],
      "metadata": {
        "id": "UGGfoN9E06tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/topic_classification.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/content') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "FZbxwIOl1AME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I split the dataset into two folders : \n",
        "1. One containing the training set : /content/topic_classification_splitted/train\n",
        "2. One containing the testing set : /content/topic_classification_splitted/test\n",
        "\n",
        "Note that I will split the first folder in two to create a validation set."
      ],
      "metadata": {
        "id": "UV5kD0Mx1Esy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aD1zzgnrQ22V"
      },
      "outputs": [],
      "source": [
        "splitfolders.ratio(r\"/content/topic_classification\",\n",
        "                   output=r\"/content/topic_classification_splitted\",\n",
        "                   seed=2504, ratio=(.8, .2), group_prefix=None, move=False)\n",
        "\n",
        "os.rename(\"/content/topic_classification_splitted/val\", \"/content/topic_classification_splitted/test\")\n",
        "\n",
        "names_classes = [f for f in listdir('/content/topic_classification_splitted/test')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I implement data augmentation on the training data and I split the training dataset in two using the radio val_ratio"
      ],
      "metadata": {
        "id": "FoasIiKW13vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "download_dir = Path(r\"/content/topic_classification_splitted\")\n",
        "train_data_dir = download_dir/'train'\n",
        "test_data_dir = download_dir/'test'\n",
        "class_subset = sorted(os.listdir(train_data_dir))\n",
        "val_ratio = 0.3\n",
        "target_size = (224, 224)\n",
        "\n",
        "# train_generator = ImageDataGenerator(validation_split=0.2,preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "                                    #  width_shift_range=0.5, \n",
        "                                    #  height_shift_range=0.5,\n",
        "                                    #  horizontal_flip=True, \n",
        "                                    #  vertical_flip=True,\n",
        "                                     validation_split= val_ratio,\n",
        "                                     preprocessing_function=preprocess_input\n",
        "                                     ) \n",
        "\n",
        "traingen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=target_size,\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='training',\n",
        "                                               batch_size=BATCH_SIZE, \n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=target_size,\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='validation',\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "testgen = test_generator.flow_from_directory(test_data_dir,\n",
        "                                             target_size=target_size,\n",
        "                                             class_mode=None,\n",
        "                                             classes=class_subset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=False,\n",
        "                                             seed=42)"
      ],
      "metadata": {
        "id": "TYMMxToj1tks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to build the architecture of the model: Eyeballer layers on top of a pre-trained model. It takes in input : \n",
        "1. The size of the images (it must match the target_size used previously\n",
        "2. The number of categories in the dataset, it is also the size of the output layer\n",
        "3. The optimizer instantiated for training (default 'RMSProp')\n",
        "4. The number of layers from the pre-trained model to unfreeze. If set to 0, all of the pre-trained will freeze"
      ],
      "metadata": {
        "id": "CAmz0W-41t_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape, n_classes):\n",
        "   \n",
        "  base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "  model = base_model.output\n",
        "  model = GlobalAveragePooling2D()(model)\n",
        "  model = Dense(256, activation=\"relu\", name=\"HiddenLayer1\")(model)\n",
        "  model = Dropout(0.5)(model)\n",
        "  model = Dense(128, activation=\"relu\", name=\"HiddenLayer2\", kernel_regularizer=regularizers.l2(0.01))(model)\n",
        "  model = Dropout(0.2)(model)\n",
        "  model = Dense(27, activation=\"softmax\", name=\"OutputLayer\")(model)\n",
        "\n",
        "  model = Model(inputs=base_model.input, outputs=model)\n",
        "\n",
        "  # optim_1 = Adam(learning_rate=0.001)\n",
        "  optim_1 = RMSprop(\n",
        "    learning_rate=0.0001,\n",
        "    rho=0.9,\n",
        "    momentum=0.0,\n",
        "    epsilon=1e-07,\n",
        "    centered=False, #True may help but computationaly expensive\n",
        "    name=\"RMSprop\",\n",
        ")\n",
        "\n",
        "  model.compile(optimizer= optim_1, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "bpSHuAEg2OE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "n_classes=27\n",
        "\n",
        "n_steps = traingen.samples // BATCH_SIZE\n",
        "n_val_steps = validgen.samples // BATCH_SIZE\n",
        "n_epochs = 30\n",
        "\n",
        "# First we'll train the model without Fine-tuning\n",
        "model = create_model(input_shape, n_classes)"
      ],
      "metadata": {
        "id": "BLB82onk2WxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks"
      ],
      "metadata": {
        "id": "ynXo-Rwj3ADl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_1 = PlotLossesCallback()\n",
        "\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath='tl_model_eyeballer.weights.best.hdf5',\n",
        "                                  save_best_only=True,\n",
        "                                  verbose=1)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,\n",
        "                           restore_best_weights=True,\n",
        "                           mode='min')"
      ],
      "metadata": {
        "id": "G5MUx9Ej2-i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(traingen,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            epochs=n_epochs,\n",
        "                            validation_data=validgen,\n",
        "                            steps_per_epoch=n_steps,\n",
        "                            validation_steps=n_val_steps,\n",
        "                            callbacks=[tl_checkpoint_1, early_stop,plot_loss_1],\n",
        "                            verbose=1)"
      ],
      "metadata": {
        "id": "Civ9XX5Y3Fac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "model.load_weights('tl_model_eyeballer.weights.best.hdf5') # initialize the best trained weights\n",
        "\n",
        "true_classes = testgen.classes\n",
        "class_indices = traingen.class_indices\n",
        "class_indices = dict((v,k) for k,v in class_indices.items())\n",
        "\n",
        "preds = model.predict(testgen)\n",
        "pred_classes = np.argmax(preds, axis=1)"
      ],
      "metadata": {
        "id": "GuFn8a213JS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3ZIYTuIQux3"
      },
      "outputs": [],
      "source": [
        "# The score results :\n",
        "print(classification_report(true_classes, pred_classes, target_names= names_classes))\n",
        "accuracy = accuracy_score(true_classes, pred_classes)\n",
        "print(\"Eyeballer Model Accuracy : {:.2f}%\".format(accuracy * 100))\n",
        "p = precision_score(true_classes, pred_classes, average='macro')\n",
        "r = recall_score(true_classes, pred_classes, average='macro')\n",
        "F1 = 2 * (p * r) / (p + r)\n",
        "print(\"Precision = \" + str(p))\n",
        "print(\"Recall = \" + str(r))\n",
        "print(\"F1 score = \" + str(F1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Eyeballer (Xception)",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}