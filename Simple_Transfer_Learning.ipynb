{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmaQuA/l/8l8E/UAKFsQD4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GuillBla/Internship_Report_Code/blob/main/Simple_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A script to execute to prevent from the limits of imposed by Google Colab"
      ],
      "metadata": {
        "id": "C7MerJF2zt8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function ConnectButton(){\n",
        "#     console.log(\"Connect pushed\"); \n",
        "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "# }\n",
        "# setInterval(ConnectButton,60000);"
      ],
      "metadata": {
        "id": "xnVWnYI7zr5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install packages on Colab"
      ],
      "metadata": {
        "id": "hULpNcluAlMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders\n",
        "# !pip install keras.utils.plot_model  \n",
        "# Uncomment the lines associated with plot_model and matplotlib.pyplot if you want a visual description of the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ1a7pqi-a1b",
        "outputId": "84146dbc-c994-4009-891d-01ef7611b5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "import splitfolders\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.applications.xception import Xception, preprocess_input\n",
        "from keras.applications.resnet import ResNet50, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "# import matplotlib.pyplot as plt\n",
        "# from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "uKyHlpGl-WJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "id": "OW6ODVFRHdtr",
        "outputId": "fd1fdef4-5bf6-426d-f318-3d71fc1a52a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-4-3b8a479202a4>\", line 1, in <module>\n",
            "    drive.mount('/content/drive')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\", line 105, in mount\n",
            "    ephemeral=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\", line 120, in _mount\n",
            "    'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\", line 171, in blocking_request\n",
            "    return read_reply_from_input(request_id, timeout_sec)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\", line 97, in read_reply_from_input\n",
            "    time.sleep(0.025)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 739, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.7/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the following folders have already been created, they need to be removed "
      ],
      "metadata": {
        "id": "tW5mMD4BJ67P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Clear the environment\n",
        "# shutil.rmtree(r'/content/topic_classification_splitted')\n",
        "# shutil.rmtree(r'/content/topic_classification')"
      ],
      "metadata": {
        "id": "Bf6cJQKhJ5VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/topic_classification.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/content') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "gAh0QighHc8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I split the dataset into two folders : \n",
        "1. One containing the training set : /content/topic_classification_splitted/train\n",
        "2. One containing the testing set : /content/topic_classification_splitted/test\n",
        "\n",
        "Note that I will split the first folder in two to create a validation set.\n"
      ],
      "metadata": {
        "id": "cMsVs-nv-kyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitfolders.ratio(r\"/content/topic_classification\",\n",
        "                   output=r\"/content/topic_classification_splitted\",\n",
        "                   seed=2504, ratio=(.8, .2), group_prefix=None, move=False)\n",
        "\n",
        "os.rename(\"/content/topic_classification_splitted/val\", \"/content/topic_classification_splitted/test\") "
      ],
      "metadata": {
        "id": "yy5tyQO3Ljw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I implement data augmentation on the training data and I split the training dataset in two using the radio val_ratio"
      ],
      "metadata": {
        "id": "RWCBDdE-_WCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "download_dir = Path(r\"/content/topic_classification_splitted\")\n",
        "train_data_dir = download_dir/'train'\n",
        "test_data_dir = download_dir/'test'\n",
        "class_subset = sorted(os.listdir(train_data_dir))\n",
        "val_ratio = 0.15\n",
        "target_size = (224, 224)\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "                                    #  rotation_range=90, \n",
        "                                    #  brightness_range=[0.1, 0.7],\n",
        "                                    #  width_shift_range=0.5, \n",
        "                                    #  height_shift_range=0.5,\n",
        "                                    #  horizontal_flip=True, \n",
        "                                    #  vertical_flip=True,\n",
        "                                     validation_split=val_ratio,\n",
        "                                     preprocessing_function=preprocess_input) # Xception preprocessing\n",
        "\n",
        "traingen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=target_size,\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='training',\n",
        "                                               batch_size=BATCH_SIZE, \n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "validgen = train_generator.flow_from_directory(train_data_dir,\n",
        "                                               target_size=target_size,\n",
        "                                               class_mode='categorical',\n",
        "                                               classes=class_subset,\n",
        "                                               subset='validation',\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               shuffle=True,\n",
        "                                               seed=42)\n",
        "\n",
        "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input) # Xception preprocessing\n",
        "\n",
        "testgen = test_generator.flow_from_directory(test_data_dir,\n",
        "                                             target_size=target_size,\n",
        "                                             class_mode=None,\n",
        "                                             classes=class_subset,\n",
        "                                             batch_size=1,\n",
        "                                             shuffle=False,\n",
        "                                             seed=42)"
      ],
      "metadata": {
        "id": "NTdQVmNVHJ-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to build the architecture of the model. It takes in input : \n",
        "1. The size of the images (it must match the target_size used previously\n",
        "2. The number of categories in the dataset, it is also the size of the output layer\n",
        "3. The optimizer instantiated for training (default 'RMSProp')\n",
        "4. The number of layers from the pre-trained model to unfreeze. If set to 0, all of the pre-trained will freeze"
      ],
      "metadata": {
        "id": "BEvxdYO7BQBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape, n_classes, optimizer='rmsprop', fine_tune=0):\n",
        "\n",
        "    # Pretrained convolutional layers are loaded using the Imagenet weights.\n",
        "    # Include_top is set to False, in order to exclude the model's fully-connected layers.\n",
        "    conv_base = Resnet50(include_top=False,\n",
        "                     weights='imagenet', \n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    # Layers in the convolutional base are switched from trainable to non-trainable\n",
        "    # depending on the size of the fine-tuning parameter.\n",
        "    if fine_tune > 0:\n",
        "        for layer in conv_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in conv_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Add layers on top of the model\n",
        "    top_model = conv_base.output\n",
        "    top_model = Flatten(name=\"flatten\")(top_model)\n",
        "    top_model = Dense(4096, activation='relu')(top_model)\n",
        "    top_model = Dense(1072, activation='relu')(top_model)\n",
        "    top_model = Dropout(0.2)(top_model)\n",
        "    output_layer = Dense(n_classes, activation='softmax')(top_model)\n",
        "\n",
        "    # Group the convolutional base and new fully-connected layers into a Model object.\n",
        "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
        "\n",
        "    # Plot the model\n",
        "    # plot_model(model, to_file='model.png',show_layer_activations=True)\n",
        "\n",
        "    # Display the image\n",
        "    # data = plt.imread('model.png')\n",
        "    # plt.imshow(data)\n",
        "    # plt.show()\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "id": "K84gy0W7Pnha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)\n",
        "optim_1 = Adam(learning_rate=0.001)\n",
        "n_classes=27\n",
        "\n",
        "n_steps = traingen.samples // BATCH_SIZE\n",
        "n_val_steps = validgen.samples // BATCH_SIZE\n",
        "n_epochs = 10\n",
        "\n",
        "# First we'll train the model without Fine-tuning\n",
        "model = create_model(input_shape, n_classes, optim_1, fine_tune=0)"
      ],
      "metadata": {
        "id": "U5mHfYByPyHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl_checkpoint_1 = ModelCheckpoint(filepath='model.weights.best.hdf5',\n",
        "                                  save_best_only=True,\n",
        "                                  verbose=1)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=10,\n",
        "                           restore_best_weights=True,\n",
        "                           mode='min')"
      ],
      "metadata": {
        "id": "TnqStxdjP5Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(traingen,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            epochs=n_epochs,\n",
        "                            validation_data=validgen,\n",
        "                            steps_per_epoch=n_steps,\n",
        "                            validation_steps=n_val_steps,\n",
        "                            callbacks=[tl_checkpoint_1, early_stop],\n",
        "                            verbose=1)"
      ],
      "metadata": {
        "id": "xvlxShkAQBAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "model.load_weights('model.weights.best.hdf5') # initialize the best trained weights\n",
        "\n",
        "true_classes = testgen.classes\n",
        "class_indices = traingen.class_indices\n",
        "class_indices = dict((v,k) for k,v in class_indices.items())\n",
        "\n",
        "preds = model.predict(testgen)\n",
        "pred_classes = np.argmax(preds, axis=1)"
      ],
      "metadata": {
        "id": "wdg_DGAFQFlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The score results :\n",
        "accuracy = accuracy_score(true_classes, pred_classes)\n",
        "print(\"Model Accuracy without Fine-Tuning: {:.2f}%\".format(accuracy * 100))\n",
        "p = precision_score(true_classes, pred_classes, average='macro')\n",
        "r = recall_score(true_classes, pred_classes, average='macro')\n",
        "F1 = 2 * (p * r) / (p + r)\n",
        "print(\"Precision = \" + str(p))\n",
        "print(\"Recall = \" + str(r))\n",
        "print(\"F1 score = \" + str(F1))"
      ],
      "metadata": {
        "id": "vhzTyZ9EQJRL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}